"""
Dynamic Depth MinMax Agent for Dots and Boxes
ê²Œì„ ì§„í–‰ë„ì— ë”°ë¼ íƒìƒ‰ ê¹Šì´ë¥¼ ë™ì ìœ¼ë¡œ ì¡°ì •í•˜ì—¬ ì†ë„ì™€ ì •í™•ë„ì˜ ê· í˜•ì„ ë§ì¶¤
"""

import random
import time
from typing import List, Optional, Sequence, Set, Tuple, Dict
from dataclasses import dataclass

from main import Move, DotsAndBoxesBoard, bitmap_to_edges


@dataclass
class GameState:
    """ê²Œì„ ìƒíƒœë¥¼ í‘œí˜„í•˜ëŠ” í´ë˜ìŠ¤"""
    edges: Set[Move]
    scores: Tuple[int, int]  # (player0, player1)
    current_player: int
    xsize: int
    ysize: int
    
    def copy(self):
        return GameState(
            edges=self.edges.copy(),
            scores=self.scores,
            current_player=self.current_player,
            xsize=self.xsize,
            ysize=self.ysize
        )


class DynamicDepthMinMaxAgent:
    """
    ë™ì  ê¹Šì´ ì¡°ì • MinMax ì•Œê³ ë¦¬ì¦˜
    - ê²Œì„ ì´ˆë°˜: ì–•ì€ íƒìƒ‰ (ë¹ ë¥¸ ì†ë„)
    - ê²Œì„ ì¤‘ë°˜: ì¤‘ê°„ íƒìƒ‰ (ê· í˜•)
    - ê²Œì„ í›„ë°˜: ê¹Šì€ íƒìƒ‰ (ì •í™•ë„)
    """
    
    def __init__(
        self, 
        seed: Optional[int] = None,
        time_limit: float = 0.8  # ì•ˆì „ ë§ˆì§„ì„ ìœ„í•´ 0.8ì´ˆ
    ):
        self._rng = random.Random(seed)
        self.time_limit = time_limit
        self.nodes_searched = 0
        self.transposition_table: Dict[frozenset, Tuple[int, float, Optional[Move]]] = {}
        self.start_time = 0.0
        
        # ê²Œì„ í†µê³„ (ë””ë²„ê¹…ìš©)
        self.total_moves = 0
        self.depth_usage = {2: 0, 3: 0, 4: 0, 5: 0}
        
    def _get_dynamic_depth(self, available_moves: int, total_edges: int) -> int:
        """
        ë‚¨ì€ ìˆ˜ì— ë”°ë¼ ë™ì ìœ¼ë¡œ íƒìƒ‰ ê¹Šì´ ê²°ì •
        
        Args:
            available_moves: ë‚¨ì€ ê°€ëŠ¥í•œ ìˆ˜ì˜ ê°œìˆ˜
            total_edges: ì „ì²´ ì„ ì˜ ê°œìˆ˜ (60ê°œ)
        
        Returns:
            ì ì ˆí•œ íƒìƒ‰ ê¹Šì´
        """
        # ê²Œì„ ì§„í–‰ë„ ê³„ì‚°
        progress = (total_edges - available_moves) / total_edges
        
        # ê²Œì„ ì´ˆë°˜ (ì§„í–‰ë„ 0-33%): ë§ì€ ì„ íƒì§€, ì–•ì€ íƒìƒ‰
        if available_moves > 40:
            return 2
        
        # ê²Œì„ ì¤‘ë°˜ (ì§„í–‰ë„ 33-75%): ì ë‹¹í•œ íƒìƒ‰
        elif available_moves > 15:
            return 3
        
        # ê²Œì„ í›„ë°˜ (ì§„í–‰ë„ 75-90%): ê¹Šì€ íƒìƒ‰
        elif available_moves > 6:
            return 4
        
        # ê²Œì„ ì¢…ë°˜ (ì§„í–‰ë„ 90-100%): ë§¤ìš° ê¹Šì€ íƒìƒ‰ ë˜ëŠ” ì™„ì „ íƒìƒ‰
        else:
            return 5
    
    def select_move(self, board_lines: Sequence, xsize: int, ysize: int) -> Move:
        """ìµœì ì˜ ìˆ˜ë¥¼ ì„ íƒ"""
        self.start_time = time.time()
        self.nodes_searched = 0
        
        edges = bitmap_to_edges(board_lines, xsize, ysize)
        board = DotsAndBoxesBoard(xsize, ysize, edges)
        moves = board.available_moves()
        
        if not moves:
            raise ValueError("ë” ì´ìƒ ë‘˜ ìˆ˜ ìˆëŠ” ì„ ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # í•œ ìˆ˜ë§Œ ë‚¨ì•˜ìœ¼ë©´ ë°”ë¡œ ë°˜í™˜
        if len(moves) == 1:
            return moves[0]
        
        # ì „ì²´ ì„ ì˜ ê°œìˆ˜ ê³„ì‚°
        total_edges = xsize * (ysize + 1) + ysize * (xsize + 1)
        
        # ë™ì ìœ¼ë¡œ ê¹Šì´ ê²°ì •
        dynamic_depth = self._get_dynamic_depth(len(moves), total_edges)
        self.depth_usage[dynamic_depth] = self.depth_usage.get(dynamic_depth, 0) + 1
        self.total_moves += 1
        
        # ì¦‰ì‹œ ë°•ìŠ¤ë¥¼ ì™„ì„±í•  ìˆ˜ ìˆëŠ” ìˆ˜ê°€ ìˆìœ¼ë©´ ìš°ì„  ì„ íƒ
        immediate_win_moves = [m for m in moves if board.boxes_completed_by_move(m) > 0]
        if immediate_win_moves:
            # ì—¬ëŸ¬ ê°œë©´ ê°€ì¥ ë§ì´ ì™„ì„±í•˜ëŠ” ìˆ˜ ì„ íƒ
            immediate_win_moves.sort(key=lambda m: -board.boxes_completed_by_move(m))
            # ê°„ë‹¨í•œ ê²½ìš°ëŠ” ë°”ë¡œ ë°˜í™˜ (ì‹œê°„ ì ˆì•½)
            if len(moves) > 20:  # ì´ˆë°˜ì´ë©´
                return immediate_win_moves[0]
        
        # ê²Œì„ ìƒíƒœ ìƒì„±
        state = GameState(
            edges=edges.copy(),
            scores=(0, 0),
            current_player=0,
            xsize=xsize,
            ysize=ysize
        )
        
        # MinMax íƒìƒ‰
        best_move = None
        best_score = float('-inf')
        alpha = float('-inf')
        beta = float('inf')
        
        # ë¬´ë¸Œ ì˜¤ë”ë§
        moves = self._order_moves(board, moves)
        
        for move in moves:
            if time.time() - self.start_time > self.time_limit * 0.9:
                break
            
            try:
                # ìˆ˜ë¥¼ ë‘ê³  í‰ê°€
                new_state, boxes_completed = self._apply_move(state, board, move)
                
                if boxes_completed > 0:
                    # ë°•ìŠ¤ë¥¼ ì™„ì„±í•˜ë©´ ê°™ì€ í”Œë ˆì´ì–´ê°€ ë‹¤ì‹œ ë‘ 
                    score = self._minimax(new_state, dynamic_depth - 1, alpha, beta, True)
                else:
                    # ìƒëŒ€ë°© ì°¨ë¡€
                    score = self._minimax(new_state, dynamic_depth - 1, alpha, beta, False)
                
                if score > best_score:
                    best_score = score
                    best_move = move
                
                alpha = max(alpha, best_score)
                
            except TimeoutError:
                break
        
        # ìµœì„ ì˜ ìˆ˜ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° í´ë°±
        if best_move is None:
            best_move = self._fallback_selection(board, moves)
        
        return best_move
    
    def _minimax(
        self, 
        state: GameState, 
        depth: int, 
        alpha: float, 
        beta: float, 
        maximizing: bool
    ) -> float:
        """MinMax with Alpha-Beta Pruning"""
        
        self.nodes_searched += 1
        
        # ì‹œê°„ ì²´í¬ (ê°€ë”ì”©ë§Œ - ì„±ëŠ¥ì„ ìœ„í•´)
        if self.nodes_searched % 1000 == 0:
            if time.time() - self.start_time > self.time_limit:
                raise TimeoutError()
        
        # Transposition Table ì²´í¬
        state_key = frozenset(state.edges)
        if state_key in self.transposition_table:
            cached_depth, cached_score, _ = self.transposition_table[state_key]
            if cached_depth >= depth:
                return cached_score
        
        board = DotsAndBoxesBoard(state.xsize, state.ysize, state.edges)
        moves = board.available_moves()
        
        # ì¢…ë£Œ ì¡°ê±´: ê¹Šì´ 0 ë˜ëŠ” ê²Œì„ ì¢…ë£Œ
        if depth == 0 or not moves:
            score = self._evaluate_state(state, board, len(moves))
            self.transposition_table[state_key] = (depth, score, None)
            return score
        
        # ë¬´ë¸Œ ì˜¤ë”ë§
        moves = self._order_moves(board, moves)
        
        if maximizing:
            max_eval = float('-inf')
            for move in moves:
                new_state, boxes_completed = self._apply_move(state, board, move)
                
                if boxes_completed > 0:
                    # ê°™ì€ í”Œë ˆì´ì–´ ê³„ì†
                    eval_score = self._minimax(new_state, depth - 1, alpha, beta, True)
                else:
                    # ìƒëŒ€ë°© ì°¨ë¡€
                    eval_score = self._minimax(new_state, depth - 1, alpha, beta, False)
                
                max_eval = max(max_eval, eval_score)
                alpha = max(alpha, eval_score)
                
                if beta <= alpha:
                    break  # Beta cut-off
            
            self.transposition_table[state_key] = (depth, max_eval, None)
            return max_eval
        else:
            min_eval = float('inf')
            for move in moves:
                new_state, boxes_completed = self._apply_move(state, board, move)
                
                if boxes_completed > 0:
                    # ìƒëŒ€ë°© ê³„ì†
                    eval_score = self._minimax(new_state, depth - 1, alpha, beta, False)
                else:
                    # í˜„ì¬ í”Œë ˆì´ì–´ ì°¨ë¡€
                    eval_score = self._minimax(new_state, depth - 1, alpha, beta, True)
                
                min_eval = min(min_eval, eval_score)
                beta = min(beta, eval_score)
                
                if beta <= alpha:
                    break  # Alpha cut-off
            
            self.transposition_table[state_key] = (depth, min_eval, None)
            return min_eval
    
    def _apply_move(self, state: GameState, board: DotsAndBoxesBoard, move: Move) -> Tuple[GameState, int]:
        """ìˆ˜ë¥¼ ì ìš©í•˜ê³  ìƒˆë¡œìš´ ìƒíƒœ ë°˜í™˜"""
        new_state = state.copy()
        new_state.edges.add(move)
        
        # ì™„ì„±ëœ ë°•ìŠ¤ ìˆ˜ ê³„ì‚°
        boxes_completed = board.boxes_completed_by_move(move)
        
        if boxes_completed > 0:
            # í˜„ì¬ í”Œë ˆì´ì–´ê°€ ì ìˆ˜ íšë“
            if state.current_player == 0:
                new_state.scores = (state.scores[0] + boxes_completed, state.scores[1])
            else:
                new_state.scores = (state.scores[0], state.scores[1] + boxes_completed)
        else:
            # í”Œë ˆì´ì–´ êµì²´
            new_state.current_player = 1 - state.current_player
        
        return new_state, boxes_completed
    
    def _evaluate_state(self, state: GameState, board: DotsAndBoxesBoard, remaining_moves: int) -> float:
        """
        ê²Œì„ ìƒíƒœ í‰ê°€ í•¨ìˆ˜ (ê°œì„ ëœ ë²„ì „)
        """
        # ê¸°ë³¸: ì ìˆ˜ ì°¨ì´
        score_diff = state.scores[0] - state.scores[1]
        
        # ê²Œì„ì´ ëë‚¬ìœ¼ë©´ í° ë³´ë„ˆìŠ¤/í˜ë„í‹°
        if remaining_moves == 0:
            if score_diff > 0:
                return 10000 + score_diff * 100
            elif score_diff < 0:
                return -10000 + score_diff * 100
            else:
                return 0
        
        # íœ´ë¦¬ìŠ¤í‹± í‰ê°€
        eval_score = score_diff * 100
        
        # ë‚¨ì€ ì›€ì§ì„ì´ ì ì„ìˆ˜ë¡ í˜„ì¬ ì ìˆ˜ê°€ ë” ì¤‘ìš”
        if remaining_moves < 10:
            eval_score = score_diff * 200
        
        # ì¶”ê°€ íœ´ë¦¬ìŠ¤í‹±ë“¤
        moves = board.available_moves()
        
        # 1. ì¦‰ì‹œ íšë“ ê°€ëŠ¥í•œ ë°•ìŠ¤
        immediate_boxes = sum(board.boxes_completed_by_move(m) for m in moves)
        if state.current_player == 0:
            eval_score += immediate_boxes * 80
        else:
            eval_score -= immediate_boxes * 80
        
        # 2. ì•ˆì „í•œ ìˆ˜ì˜ ê°œìˆ˜
        safe_moves = sum(1 for m in moves if board.danger_score(m) == 0)
        eval_score += safe_moves * 3
        
        # 3. ìœ„í—˜í•œ ë°•ìŠ¤ ìˆ˜ (2ê°œ ì„ ì´ ê·¸ì–´ì§„ ë°•ìŠ¤)
        dangerous_boxes = 0
        for x in range(state.xsize):
            for y in range(state.ysize):
                edges_count = board.count_edges_of_square((x, y))
                if edges_count == 2:
                    dangerous_boxes += 1
                elif edges_count == 3:
                    # 3ê°œ ì„ ì´ ê·¸ì–´ì§„ ë°•ìŠ¤ëŠ” ë§¤ìš° ìœ„í—˜
                    dangerous_boxes += 3
        
        eval_score -= dangerous_boxes * 5
        
        return eval_score
    
    def _order_moves(self, board: DotsAndBoxesBoard, moves: List[Move]) -> List[Move]:
        """
        ë¬´ë¸Œ ì˜¤ë”ë§: ë” ìœ ë§í•œ ìˆ˜ë¥¼ ë¨¼ì € íƒìƒ‰ (Alpha-Beta íš¨ìœ¨ ì¦ê°€)
        """
        def move_priority(move: Move) -> Tuple[int, int, int, float]:
            # 1. ë°•ìŠ¤ë¥¼ ì™„ì„±í•˜ëŠ” ìˆ˜ (ê°€ì¥ ìš°ì„ , ë§ì´ ì™„ì„±í• ìˆ˜ë¡ ì¢‹ìŒ)
            boxes = board.boxes_completed_by_move(move)
            
            # 2. 3ê°œ ì„ ì´ ê·¸ì–´ì§„ ë°•ìŠ¤ì— ì¸ì ‘í•œ ìˆ˜ëŠ” í”¼í•˜ê¸° (ìƒëŒ€ì—ê²Œ ê¸°íšŒ ì œê³µ)
            adjacent_three_edge_boxes = 0
            for square in board.adjacent_squares(move):
                if board.count_edges_of_square(square) == 3:
                    adjacent_three_edge_boxes += 1
            
            # 3. ìœ„í—˜ë„ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
            danger = board.danger_score(move)
            
            # 4. ëœë¤ íƒ€ì´ë¸Œë ˆì´ì»¤
            random_tie = self._rng.random()
            
            # ë°•ìŠ¤ ì™„ì„±ì´ ìµœìš°ì„ , ê·¸ ë‹¤ìŒì€ 3ê°œ ì„  ë°•ìŠ¤ íšŒí”¼, ê·¸ ë‹¤ìŒì€ ìœ„í—˜ë„
            return (-boxes, adjacent_three_edge_boxes, danger, random_tie)
        
        return sorted(moves, key=move_priority)
    
    def _fallback_selection(self, board: DotsAndBoxesBoard, moves: List[Move]) -> Move:
        """ì‹œê°„ ì´ˆê³¼ ë“±ì˜ ê²½ìš° í´ë°± íœ´ë¦¬ìŠ¤í‹± ì„ íƒ"""
        self._rng.shuffle(moves)
        
        # 1. ë°•ìŠ¤ë¥¼ ì™„ì„±í•˜ëŠ” ìˆ˜
        closing_moves = [m for m in moves if board.boxes_completed_by_move(m) > 0]
        if closing_moves:
            closing_moves.sort(key=lambda m: (-board.boxes_completed_by_move(m), self._rng.random()))
            return closing_moves[0]
        
        # 2. ì•ˆì „í•œ ìˆ˜ (ìœ„í—˜ë„ 0)
        safe_moves = [m for m in moves if board.danger_score(m) == 0]
        if safe_moves:
            return self._rng.choice(safe_moves)
        
        # 3. ê°€ì¥ ëœ ìœ„í—˜í•œ ìˆ˜
        moves.sort(key=lambda m: (board.danger_score(m), self._rng.random()))
        return moves[0]
    
    def print_stats(self):
        """ê²Œì„ í†µê³„ ì¶œë ¥ (ë””ë²„ê¹…ìš©)"""
        if self.total_moves > 0:
            print(f"\nğŸ“Š MinMax ê¹Šì´ ì‚¬ìš© í†µê³„ (ì´ {self.total_moves}ìˆ˜):")
            for depth in sorted(self.depth_usage.keys()):
                count = self.depth_usage.get(depth, 0)
                percentage = (count / self.total_moves) * 100
                print(f"  Depth {depth}: {count}íšŒ ({percentage:.1f}%)")


# main.pyì™€ í˜¸í™˜ë˜ëŠ” ì¸í„°í˜ì´ìŠ¤
model: Optional[DynamicDepthMinMaxAgent] = None


def init():
    global model
    model = DynamicDepthMinMaxAgent(time_limit=0.8)


def run(board_lines, xsize, ysize):
    if model is None:
        init()
    move = model.select_move(board_lines, xsize, ysize)
    return [move.x, move.y, move.z]

